{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dabfb61-8e59-4b51-a5cb-b02d7f12b240",
   "metadata": {},
   "source": [
    "# Donkey Car IMU Model\n",
    "\n",
    "Build and run a Keras model copied from Donkey Car.\n",
    "\n",
    "* The IMU model has been modified to accept larger telemetry inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a186988-1c64-48d0-984a-6c15b299587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 01:03:48.976839: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "# import tensorflow_addons as tfa\n",
    "import time\n",
    "import pickle\n",
    "import sklearn.metrics as metrics\n",
    "from os import remove\n",
    "from os.path import exists\n",
    "\n",
    "from modeling_methods import run_model, plot_metrics, save_model, create_donkey_vimu, create_normed_donkey_vimu\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from tensorflow.keras.metrics import MAE, MSE, RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop\n",
    "from tensorflow_addons.optimizers import AdamW, RectifiedAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fea7035-b9f3-468f-a45b-a73a41361ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb5092b-eea1-4842-88b0-06e113d7e87f",
   "metadata": {},
   "source": [
    "## Directories/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb758b89-e437-47a8-97c4-7f5e3d761a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Fill in your own here\n",
    "dataset_directory = '../data/datasets/05_09_2022/00_47_15'\n",
    "dropbox_directory = '/home/grant/Dropbox/Projects/DonkeyCar' # None if not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b55e9ee-384c-438d-bc75-370fb3403682",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e91105-a195-4dcf-b56e-edf34ebb0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {\n",
    "    'minmax': MinMaxScaler,\n",
    "    'robust': RobustScaler,\n",
    "    'standard': StandardScaler,\n",
    "}\n",
    "models = {\n",
    "    'vimu': create_donkey_vimu,\n",
    "    'normed_vimu': create_normed_donkey_vimu\n",
    "}\n",
    "\n",
    "optimizers = {\n",
    "    'Adam': Adam(learning_rate=0.0001, amsgrad=True),\n",
    "    # 'AdamW': AdamW(amsgrad=True), # default learning rate (0.001)\n",
    "    'Nadam': Nadam(learning_rate=0.0001),\n",
    "    'Radam': RectifiedAdam(learning_rate=0.0001), # default learning rate: 0.001\n",
    "    'RMSProp': RMSprop()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3332748e-3048-4bd5-8e7c-5e99aedafb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directories\n",
    "model_directory = f'../models'\n",
    "\n",
    "if dropbox_directory:\n",
    "    dropbox_model_directory = f'{dropbox_directory}/models'\n",
    "    \n",
    "## File paths\n",
    "cam_input_dataset_file = f'{dataset_directory}/X_img.npy'\n",
    "telem_input_dataset_file = f'{dataset_directory}/X_telem.pkl'\n",
    "target_dataset_file = f'{dataset_directory}/y.npy'\n",
    "\n",
    "## Parameters\n",
    "model_type = 'vimu'\n",
    "scaler_type = 'robust' # minmax/robust/standard \n",
    "optimizer_type = 'Adam'\n",
    "\n",
    "batch_sizes = [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2, 1]\n",
    "# batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "# batch_sizes = [1024, 512, 256, 128,] # 64, 32, 16, 8, 4]\n",
    "epochs = 2000\n",
    "early_stop_patience = 200 # None for no stop\n",
    "dual_outputs = False\n",
    "plot_results = False\n",
    "verbose = 1 # 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7044eb84-a366-461b-8dd2-1864afbe970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model = models[model_type]\n",
    "optimizer = optimizers[optimizer_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66a8ab-bbb0-4f96-ba3d-ba42832a9346",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b8488-ad46-4de0-a67f-d89c9c98912a",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "451f5725-213b-4492-bc82-202c86181efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telemetry columns: Index(['speed', 'pitch', 'yaw', 'roll', 'first_lap'], dtype='object')\n",
      "X_cam.shape = (100000, 120, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "## Load the datasets\n",
    "X_cam = np.load(cam_input_dataset_file, allow_pickle=True)#.astype('uint8')\n",
    "\n",
    "## Load telemetry as df to grab telemetry column names\n",
    "telem_df = pd.read_pickle(telem_input_dataset_file).copy()\n",
    "telemetry_columns = telem_df.columns\n",
    "print(f'Telemetry columns: {telemetry_columns}')\n",
    "## Convert to numpy, delete df\n",
    "X_telem = telem_df.to_numpy() #.astype('float32')\n",
    "\n",
    "telem_df = None\n",
    "del telem_df\n",
    "\n",
    "## Load targets\n",
    "y = np.load(target_dataset_file, mmap_mode='r')\n",
    "\n",
    "## Check Shape\n",
    "print(f'{X_cam.shape = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9024459d-2092-4448-b76b-1163bac9130b",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30558a03-f187-479b-9fea-eea61290f67f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dual_outputs:\n",
    "    # steering = y[:, 0], throttle = y[:, 1]\n",
    "    datasets = train_test_split(X_cam, X_telem, y[:, 0], y[:, 1], test_size=0.2, random_state=seed)\n",
    "else:\n",
    "    datasets = train_test_split(X_cam, X_telem, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "X_telem = None\n",
    "X_cam = None\n",
    "y = None\n",
    "del X_telem\n",
    "del X_cam\n",
    "del y\n",
    "    \n",
    "X_cam_train = datasets[0]\n",
    "X_cam_test = datasets[1]\n",
    "X_telem_train = datasets[2]\n",
    "X_telem_test = datasets[3]\n",
    "    \n",
    "if dual_outputs:\n",
    "    y_st_train = datasets[4]\n",
    "    y_st_test = datasets[5]\n",
    "    y_th_train = datasets[6]\n",
    "    y_th_test = datasets[7]\n",
    "else:\n",
    "    y_train = datasets[4]\n",
    "    y_test = datasets[5]\n",
    "    \n",
    "datasets = None\n",
    "del datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c490dd36-446a-4acc-a61c-0a3faa4c5df9",
   "metadata": {},
   "source": [
    "### Pre-Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40ddfc67-74e4-4598-b309-2801c71ce36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler_file = 'robust_scaler_05_09_01_03.pkl'\n"
     ]
    }
   ],
   "source": [
    "if scaler_type:\n",
    "\n",
    "    scaler_file = f'{scaler_type}_scaler_{time.strftime(\"%m_%d_%H_%M\")}.pkl'\n",
    "    scaler_path = f'../scalers/{scaler_file}'\n",
    "\n",
    "    if dropbox_directory:\n",
    "        dropbox_scaler_path = f'{dropbox_directory}/scalers/{scaler_file}'\n",
    "\n",
    "    sc = scalers[scaler_type]()\n",
    "\n",
    "    sc.fit(X_telem_train)\n",
    "    X_telem_train = sc.fit_transform(X_telem_train)\n",
    "    X_telem_test = sc.transform(X_telem_test)\n",
    "\n",
    "    ## Save scaler as a pickle\n",
    "    pickle.dump(sc, open(scaler_path, 'wb'))\n",
    "\n",
    "    if dropbox_directory:\n",
    "        pickle.dump(sc, open(dropbox_scaler_path, 'wb'))\n",
    "\n",
    "    ## Print path\n",
    "    print(f'{scaler_file = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd46a7b-3435-4a05-afcc-274e3af58264",
   "metadata": {},
   "source": [
    "### Get Input Shape(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fdd5661-6a71-4f7e-a556-0909412dbf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(X_cam_train)):\n",
    "#     X_cam_train[i] = np.asarray(X_cam_train[i], dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf0dd59d-cac9-40d8-9999-ad727d50e35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 160, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cam_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bad8334-6b73-422a-8be8-3d2eed7f7efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.74049934e-01,  2.32142997e-04,  9.17855359e-02, -9.78644080e-01,\n",
       "        0.00000000e+00])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_telem_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "576a58b8-4b6b-4123-b4ad-9a4a83df348a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_input_shape=(120, 160, 1)\n",
      "tel_input_shape=(5,)\n"
     ]
    }
   ],
   "source": [
    "## Create variables\n",
    "img_input_shape = X_cam_train[0].shape\n",
    "tel_input_shape = X_telem_train[0].shape\n",
    "\n",
    "## Check input shapes\n",
    "print(f'{img_input_shape=}')\n",
    "print(f'{tel_input_shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1195431a-ec35-4383-8156-e1c3e5b9231f",
   "metadata": {},
   "source": [
    "### Convert Numpy Arrays to Tensors\n",
    "If nothing else, this keeps the info and warning messages from cluttering the training output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c535a8d-9c31-438b-9691-7f7b04dfac69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 01:03:52.693253: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-09 01:03:52.725344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 01:03:52.725594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 6GB computeCapability: 6.1\n",
      "coreClock: 1.797GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-05-09 01:03:52.725613: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-09 01:03:52.729022: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-05-09 01:03:52.729080: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-05-09 01:03:52.754386: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-09 01:03:52.754758: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-09 01:03:52.755190: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-05-09 01:03:52.755852: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-05-09 01:03:52.755972: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-05-09 01:03:52.756077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 01:03:52.756346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 01:03:52.756436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-05-09 01:03:52.757155: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-09 01:03:52.757431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 01:03:52.757656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 6GB computeCapability: 6.1\n",
      "coreClock: 1.797GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-05-09 01:03:52.757724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 01:03:52.758011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 01:03:52.758249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-05-09 01:03:52.758282: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-09 01:03:53.198154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-09 01:03:53.198179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-05-09 01:03:53.198185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-05-09 01:03:53.198380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 01:03:53.198560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 01:03:53.198700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 01:03:53.198801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4634 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-05-09 01:03:53.199789: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1536000000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "X_cam_train = tf.constant(X_cam_train.astype('uint8')) #.astype('uint8'))\n",
    "X_telem_train = tf.constant(X_telem_train) #.astype('float32')) #.astype('float32')\n",
    "X_cam_test = tf.constant(X_cam_test.astype('uint8')) #.astype('uint8'))\n",
    "X_telem_test = tf.constant(X_telem_test) #.astype('float32')) #.astype('float32')\n",
    "   \n",
    "    \n",
    "# if dual_outputs:\n",
    "    \n",
    "#     y_st_train_tensor = tf.constant(y_st_train) # .astype('float32'))\n",
    "#     y_st_test_tensor = tf.constant(y_st_test) #.astype('float32'))\n",
    "#     y_th_train_tensor = tf.constant(y_th_train) #.astype('float32'))\n",
    "#     y_th_test_tensor = tf.constant(y_th_test) #.astype('float32'))\n",
    "  \n",
    "#     y_train = (y_st_train_tensor, y_th_train_tensor)\n",
    "#     y_test = (y_st_test_tensor, y_th_test_tensor)\n",
    "\n",
    "#     del [y_st_train, y_st_test, y_th_train, y_th_test]    \n",
    "    \n",
    "# else:\n",
    "\n",
    "#     y_train = tf.constant(y_train) #.astype('float32')\n",
    "#     y_test = tf.constant(y_test) #.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed19bf08-7550-4640-b8e3-9c43c91c6341",
   "metadata": {},
   "source": [
    "### Restore Interrupted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db3b83b-a0fd-4b47-988c-3b14c8c40fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "# checkpoint_filepath = '../models/checkpoint'\n",
    "# best_model = load_model(checkpoint_filepath)\n",
    "# best_results = best_model.evaluate((X_cam_test, X_telem_test_sc), y_test, batch_size=1, return_dict=True)\n",
    "# # shutil.rmtree(checkpoint_filepath)\n",
    "# best_model\n",
    "\n",
    "# model_file = save_model(model_directory=model_directory, \n",
    "#                         model=best_model, \n",
    "#                         results=best_results, \n",
    "#                         batch_size=1, \n",
    "#                         dual_outputs=dual_outputs, \n",
    "#                         scaler_file=scaler_file, \n",
    "#                         telemetry_columns=telemetry_columns,\n",
    "#                         dataset_directory=dataset_directory)\n",
    "# model_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ada31-38b8-4741-8e56-6c0c8038777b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0febfbaa-d815-45d4-9c60-7c069f767e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size 1024 start: 01:03:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 01:03:54.467488: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-05-09 01:03:54.487206: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3397935000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 01:03:55.257239: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-05-09 01:03:55.498061: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2022-05-09 01:03:55.530104: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-05-09 01:03:56.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/79 [======>.......................] - ETA: 14s - loss: 0.4705 - root_mean_squared_error: 0.6860 - mae: 0.5622"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_140097/303056270.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                   \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                   metrics=[RootMeanSquaredError(), 'mae'])\n\u001b[0;32m---> 13\u001b[0;31m     model, metrics, results = run_model(model=model,\n\u001b[0m\u001b[1;32m     14\u001b[0m                                         \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cam_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_telem_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                         \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/vrl/code/modeling_methods.py\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, X_train, y_train, X_test, y_test, batch_size, epochs, early_stop_patience, verbose)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mstop_early\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop_patience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_early\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 _r=1):\n\u001b[1;32m   1177\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Run models for each batch size\n",
    "# print('---')\n",
    "for batch_size in batch_sizes:\n",
    "    print(f'Batch size {batch_size} start: {time.strftime(\"%H:%M:%S\")}')\n",
    "    model = create_model(img_input_shape=img_input_shape,\n",
    "                         tel_input_shape=tel_input_shape, \n",
    "                         dual_outputs=dual_outputs,\n",
    "                         x_train=X_telem_train,\n",
    "                         batch_size=batch_size) \n",
    "    model.compile(loss='mse', \n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[RootMeanSquaredError(), 'mae'])\n",
    "    model, metrics, results = run_model(model=model,\n",
    "                                        X_train=(X_cam_train, X_telem_train), \n",
    "                                        y_train=y_train, \n",
    "                                        X_test=(X_cam_test, X_telem_test), \n",
    "                                        y_test=y_test, \n",
    "                                        batch_size=batch_size, \n",
    "                                        epochs=epochs,\n",
    "                                        early_stop_patience=early_stop_patience,\n",
    "                                        verbose=verbose)\n",
    "    model_file = save_model(model_directory=model_directory, \n",
    "                            model=model, \n",
    "                            results=metrics, \n",
    "                            batch_size=batch_size, \n",
    "                            dual_outputs=dual_outputs, \n",
    "                            # scaler_file=scaler_file, \n",
    "                            telemetry_columns=telemetry_columns,\n",
    "                            dataset_directory=dataset_directory,\n",
    "                            dropbox_model_directory=dropbox_model_directory)\n",
    "    history = {k: v for k, v in results.history.items()}\n",
    "    print(f'Batch size {batch_size} end:   {time.strftime(\"%H:%M:%S\")}')\n",
    "    print(f'Epochs run: {len(history[\"loss\"])}')\n",
    "    print(f'model: {model_file}')\n",
    "    print('---')\n",
    "    if plot_results:\n",
    "        plot_metrics(history=history, \n",
    "                     batch_size=batch_size, \n",
    "                     dual_outputs=dual_outputs)\n",
    "    history = None\n",
    "    model = None\n",
    "    results = None\n",
    "    del history\n",
    "    del model\n",
    "    del results\n",
    "    # K.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
