{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dabfb61-8e59-4b51-a5cb-b02d7f12b240",
   "metadata": {},
   "source": [
    "# Donkey Car IMU Model\n",
    "\n",
    "Build and run a Keras model copied from Donkey Car.\n",
    "\n",
    "* The IMU model has been modified to accept larger telemetry inputs\n",
    "* RNN-LSTM has been modified to accept IMU/telemetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a186988-1c64-48d0-984a-6c15b299587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pickle\n",
    "import sklearn.metrics as metrics\n",
    "from os.path import exists\n",
    "\n",
    "from modeling_methods import run_model, plot_metrics, save_model, create_donkey_vimu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from tensorflow.keras.metrics import MAE, MSE, RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb5092b-eea1-4842-88b0-06e113d7e87f",
   "metadata": {},
   "source": [
    "## Directories/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb758b89-e437-47a8-97c4-7f5e3d761a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill in your own here\n",
    "dataset_directory = '../data/01_28_2022/11_34_57'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db63f4ff-a88a-47b4-9400-b2c706a22932",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directories\n",
    "model_directory = f'../models'\n",
    "\n",
    "## File paths\n",
    "cam_input_dataset_file = f'{dataset_directory}/X_img.npy'\n",
    "telem_input_dataset_file = f'{dataset_directory}/X_telem.pkl'\n",
    "target_dataset_file = f'{dataset_directory}/y.npy'\n",
    "\n",
    "## Parameters\n",
    "scaler_type = 'robust' # minmax/robust/standard \n",
    "batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128, 256 , 512, 1024, 2048]\n",
    "# batch_sizes = [16, 32, 64, 128, 256, 512, ] # 1024, 2048]\n",
    "early_stop_patience = 5 # None for no stop\n",
    "epochs = 250\n",
    "dual_outputs = False\n",
    "create_model = create_donkey_vimu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e91105-a195-4dcf-b56e-edf34ebb0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {\n",
    "    'minmax': MinMaxScaler,\n",
    "    'robust': RobustScaler,\n",
    "    'standard': StandardScaler,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66a8ab-bbb0-4f96-ba3d-ba42832a9346",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b8488-ad46-4de0-a67f-d89c9c98912a",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451f5725-213b-4492-bc82-202c86181efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214894, 120, 160, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the datasets\n",
    "X_cam = np.load(cam_input_dataset_file).astype('uint8')\n",
    "\n",
    "## Load telemetry as df to grab telemetry column names\n",
    "telem_df = pd.read_pickle(telem_input_dataset_file)\n",
    "telemetry_columns = telem_df.columns\n",
    "## Convert to numpy, delete df\n",
    "X_telem = telem_df.to_numpy().astype('float32')\n",
    "del telem_df\n",
    "\n",
    "## Load targets\n",
    "y = np.load(target_dataset_file, mmap_mode='r')\n",
    "\n",
    "## Check Shape\n",
    "X_cam.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9024459d-2092-4448-b76b-1163bac9130b",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30558a03-f187-479b-9fea-eea61290f67f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dual_outputs:\n",
    "    # steering = y[:, 0], throttle = y[:, 1]\n",
    "    datasets = train_test_split(X_cam, X_telem, y[:, 0], y[:, 1], test_size=0.2, random_state=0)\n",
    "else:\n",
    "    datasets = train_test_split(X_cam, X_telem, y, test_size=0.2, random_state=0)\n",
    "\n",
    "del X_telem\n",
    "del X_cam\n",
    "    \n",
    "X_cam_train = datasets[0]\n",
    "X_cam_test = datasets[1]\n",
    "X_telem_train = datasets[2]\n",
    "X_telem_test = datasets[3]\n",
    "y_train = datasets[4]\n",
    "y_test = datasets[5]\n",
    "    \n",
    "if dual_outputs:\n",
    "    y_st_train = datasets[4]\n",
    "    y_st_test = datasets[5]\n",
    "    y_th_train = datasets[6]\n",
    "    y_th_test = datasets[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001361f5-0f0a-496e-8e26-846e12c0be7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scale IMU Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "676b1e05-40e4-4cf0-986d-4b5094637c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler_file = f'{scaler_type}_scaler_{time.strftime(\"%m_%d_%H_%M\")}.pkl'\n",
    "scaler_path = f'../scalers/{scaler_file}'\n",
    "\n",
    "sc = scalers[scaler_type]()\n",
    "    \n",
    "## Fit to then and transform training data\n",
    "X_telem_train_sc = sc.fit_transform(X_telem_train)\n",
    "## Transform testing data\n",
    "X_telem_test_sc = sc.transform(X_telem_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a507fa-f488-442a-bcc2-9943507140be",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save the Scaler for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ac8d37d-8624-4631-8246-f8079cb91f28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'robust_scaler_01_28_11_45.pkl'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save as pickle\n",
    "pickle.dump(sc, open(scaler_path, 'wb'))\n",
    "\n",
    "## Print path\n",
    "scaler_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd46a7b-3435-4a05-afcc-274e3af58264",
   "metadata": {},
   "source": [
    "### Get Input Shape(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576a58b8-4b6b-4123-b4ad-9a4a83df348a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 160, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create variables\n",
    "img_input_shape = X_cam_train[0].shape\n",
    "tel_input_shape = X_telem_train_sc[0].shape\n",
    "\n",
    "## Check telemetry input shape\n",
    "img_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "290db956-ab4c-4e61-84da-293531f4c1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171915, 120, 160, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cam_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abcfe0ac-cdea-4303-8bd0-495b8992acae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_telem_train_sc.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c535a8d-9c31-438b-9691-7f7b04dfac69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-28 11:46:00.218759: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-28 11:46:00.235220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-28 11:46:00.322705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-28 11:46:00.323023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 6GB computeCapability: 6.1\n",
      "coreClock: 1.797GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-01-28 11:46:00.323050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-28 11:46:00.484085: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-28 11:46:00.484186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-28 11:46:00.641894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-28 11:46:00.716190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-28 11:46:00.888361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-28 11:46:00.953086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-28 11:46:01.262996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-28 11:46:01.263166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-28 11:46:01.263393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-28 11:46:01.263510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-28 11:46:01.276798: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-28 11:46:01.290219: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-28 11:46:01.290414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-28 11:46:01.290612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 6GB computeCapability: 6.1\n",
      "coreClock: 1.797GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-01-28 11:46:01.290658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-28 11:46:01.290700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-28 11:46:01.290735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-28 11:46:01.290769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-28 11:46:01.290802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-28 11:46:01.290837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-28 11:46:01.290870: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-28 11:46:01.290916: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-28 11:46:01.291034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-28 11:46:01.291404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-28 11:46:01.291675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-28 11:46:01.291724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-28 11:46:03.957877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-28 11:46:03.957906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-01-28 11:46:03.957912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-01-28 11:46:03.958103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-28 11:46:03.958270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-28 11:46:03.958411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-28 11:46:03.958520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5044 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-01-28 11:46:03.970593: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 3300768000 exceeds 10% of free system memory.\n",
      "2022-01-28 11:46:05.699634: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 3300787200 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "X_cam_train_tensor = tf.constant(X_cam_train.astype('uint8'))\n",
    "X_telem_train_tensor = tf.constant(X_telem_train_sc.astype('uint8'))\n",
    "X_cam_test_tensor = tf.constant(X_cam_test.astype('float32'))\n",
    "X_telem_test_tensor = tf.constant(X_telem_test_sc.astype('float32'))\n",
    "y_train_tensor = tf.constant(y_train.astype('float32'))\n",
    "y_test_tensor = tf.constant(y_test.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b21555-5c88-4491-847e-6e8c199e4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_ds = tf.data.Dataset.from_tensor_slices((X_cam_train_tensor, X_telem_train_tensor))\n",
    "# X_test_ds = tf.data.Dataset.from_tensor_slices((X_cam_test_tensor, X_telem_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab7c7e-c757-4cdc-b555-9ba2ffb4d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.RaggedTensor.from_tensor(X_cam_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3707f8e3-a681-4c9c-aff8-4d1c40ca924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_cam_train_tensor[None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651cf333-0a32-442c-89cb-192b4c232bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_data = tf.data.Dataset.from_tensor_slices(({\"img_in\": X_cam_train, \"tel_in\": X_telem_train_sc}, y_train))\n",
    "# test_data = tf.data.Dataset.from_tensor_slices(({\"img_in\": X_cam_test, \"tel_in\": X_telem_test_sc}, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd5811-182a-44ee-bf2c-dfc5a08b5e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_data = tf.data.Dataset.from_tensor_slices(({\"img_in\": X_cam_train, \"tel_in\": X_telem_train_sc}, y_train))\n",
    "# test_data = tf.data.Dataset.from_tensor_slices(({\"img_in\": X_cam_test, \"tel_in\": X_telem_test_sc}, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3813360a-bee1-4d3f-83a4-ef9fc57c8ea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train_ds, y_train_tensor))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((X_test_ds, y_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad59f7d0-ebad-4a57-b4e2-6d242896fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = tf.data.Dataset.from_tensor_slices((tf.ragged.constant([X_test, y_test]), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ada31-38b8-4741-8e56-6c0c8038777b",
   "metadata": {},
   "source": [
    "## Model Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0febfbaa-d815-45d4-9c60-7c069f767e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Batch size 1 start: 11:46:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-28 11:46:20.192266: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-01-28 11:46:20.211086: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3398170000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-28 11:46:21.171480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-28 11:46:21.946074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171915/171915 [==============================] - 656s 4ms/step - loss: 0.2757 - mae: 0.2108 - root_mean_squared_error: 0.4888 - val_loss: 0.0068 - val_mae: 0.0450 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 2/250\n",
      "171915/171915 [==============================] - 651s 4ms/step - loss: 0.0128 - mae: 0.0697 - root_mean_squared_error: 0.1131 - val_loss: 0.0049 - val_mae: 0.0346 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 3/250\n",
      "171915/171915 [==============================] - 649s 4ms/step - loss: 0.0098 - mae: 0.0557 - root_mean_squared_error: 0.0988 - val_loss: 0.0043 - val_mae: 0.0310 - val_root_mean_squared_error: 0.0656\n",
      "Epoch 4/250\n",
      " 71369/171915 [===========>..................] - ETA: 5:33 - loss: 0.0091 - mae: 0.0509 - root_mean_squared_error: 0.0953"
     ]
    }
   ],
   "source": [
    "X_train = (X_cam_train_tensor, X_telem_train_tensor)\n",
    "X_test = (X_cam_test_tensor, X_telem_test_tensor)\n",
    "y_train = y_train_tensor\n",
    "y_test = y_test_tensor\n",
    "\n",
    "# X_train = (X_cam_train.astype('float32'), X_telem_train_sc.astype('float32'))\n",
    "# X_test = (X_cam_test.astype('float32'), X_telem_test_sc.astype('float32'))\n",
    "# y_train = y_train.astype('float32')\n",
    "# y_test = y_test.astype('float32')\n",
    "\n",
    "\n",
    "# if dual_outputs:\n",
    "#     y_train = (y_st_train, y_th_train)\n",
    "#     y_test = (y_st_test, y_th_test)\n",
    "# else:\n",
    "#     y_train = y_train\n",
    "#     y_test = y_test\n",
    "    \n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "\n",
    "## Run models for each batch size\n",
    "print('---')\n",
    "for batch_size in batch_sizes:\n",
    "    print(f'Batch size {batch_size} start: {time.strftime(\"%H:%M:%S\")}')\n",
    "    model = create_model(img_input_shape, tel_input_shape, dual_outputs)\n",
    "    model.compile(loss='mse', \n",
    "                  optimizer=Adam(learning_rate=0.0001), \n",
    "                  metrics=['mae', RootMeanSquaredError()])\n",
    "    model, results = run_model(model, X_train, y_train, X_test, y_test, \n",
    "                               batch_size, epochs,\n",
    "                              early_stop_patience=early_stop_patience)\n",
    "    # model, results = run_model(model, train_data, test_data, \n",
    "    #                        batch_size, epochs,\n",
    "    #                       early_stop_patience=early_stop_patience)\n",
    "\n",
    "    model_file = save_model(model_directory, model, results, batch_size, \n",
    "                            dual_outputs, scaler_file, telemetry_columns,\n",
    "                            dataset_directory)\n",
    "    history = {k: v for k, v in results.history.items()}\n",
    "    plot_metrics(history, batch_size, dual_outputs)\n",
    "    print(f'Batch size {batch_size} end:   {time.strftime(\"%H:%M:%S\")}')\n",
    "    print(f'Epochs run: {len(history[\"loss\"])}')\n",
    "    print(f'model: {model_file}')\n",
    "    print('---')\n",
    "    del model\n",
    "    del results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
